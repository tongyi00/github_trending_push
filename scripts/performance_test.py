#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬ - å¯¹æ¯”åŒæ­¥ä¸å¼‚æ­¥ç‰ˆæœ¬çš„æ€§èƒ½å·®å¼‚
"""
import os
import sys
import time
import asyncio
from pathlib import Path
from loguru import logger
project_root = Path(__file__).parent.parent
os.chdir(project_root)
sys.path.insert(0, str(project_root))
from src.collectors import AsyncScraperTrending, ScraperTrending
from src.analyzers import AsyncAISummarizer


async def test_async_scraper():
    """æµ‹è¯•å¼‚æ­¥çˆ¬è™«æ€§èƒ½"""
    logger.info("=== Testing Async Scraper ===")
    scraper = AsyncScraperTrending(max_concurrent=5)

    start_time = time.time()
    results = await scraper.scrape_all_ranges(['daily'])
    elapsed = time.time() - start_time

    total_repos = sum(len(repos) for repos in results.values())
    logger.info(f"Async Scraper: {total_repos} repos in {elapsed:.2f}s")

    return elapsed, total_repos


def test_sync_scraper():
    """æµ‹è¯•åŒæ­¥çˆ¬è™«æ€§èƒ½"""
    logger.info("=== Testing Sync Scraper ===")
    scraper = ScraperTrending()

    start_time = time.time()
    repos = scraper.scrape_trending_by_range(since='daily')
    elapsed = time.time() - start_time

    logger.info(f"Sync Scraper: {len(repos)} repos in {elapsed:.2f}s")

    return elapsed, len(repos)


async def test_async_ai_summarizer(repos):
    """æµ‹è¯•å¼‚æ­¥ AI æ‘˜è¦ç”Ÿæˆæ€§èƒ½"""
    logger.info("=== Testing Async AI Summarizer ===")

    summarizer = AsyncAISummarizer(max_concurrent=5)

    start_time = time.time()
    results = await summarizer.batch_summarize(repos[:5])
    elapsed = time.time() - start_time

    await summarizer.close()

    logger.info(f"Async AI Summarizer: {len(results)} summaries in {elapsed:.2f}s")

    return elapsed, len(results)


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("Starting performance comparison tests...")

    # 1. æµ‹è¯•çˆ¬è™«æ€§èƒ½
    sync_scraper_time, sync_repo_count = test_sync_scraper()
    async_scraper_time, async_repo_count = await test_async_scraper()

    scraper_speedup = sync_scraper_time / async_scraper_time if async_scraper_time > 0 else 0

    # è·å–é¡¹ç›®åˆ—è¡¨ç”¨äº AI æµ‹è¯•
    scraper = ScraperTrending()
    repos = scraper.scrape_trending_by_range(since='daily')

    # 2. æµ‹è¯• AI æ‘˜è¦æ€§èƒ½ï¼ˆä»…å¼‚æ­¥ç‰ˆæœ¬ï¼‰
    if len(repos) >= 5:
        logger.info("=== Testing Async AI Summarizer ===")
        start_time = time.time()

        summarizer = AsyncAISummarizer(max_concurrent=5)
        results = await summarizer.batch_summarize(repos[:5])
        await summarizer.close()

        async_ai_time = time.time() - start_time
        async_summary_count = len(results)

        logger.info(f"Async AI Summarizer: {async_summary_count} summaries in {async_ai_time:.2f}s")
    else:
        logger.warning("Not enough repos for AI testing")
        async_ai_time = async_summary_count = 0

    # ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š
    logger.info("\n" + "="*60)
    logger.info("PERFORMANCE TEST RESULTS")
    logger.info("="*60)
    logger.info(f"\nğŸ“Š Scraper Performance:")
    logger.info(f"  Sync:  {sync_scraper_time:.2f}s ({sync_repo_count} repos)")
    logger.info(f"  Async: {async_scraper_time:.2f}s ({async_repo_count} repos)")
    logger.info(f"  Speedup: {scraper_speedup:.2f}x")

    if async_ai_time > 0:
        logger.info(f"\nğŸ¤– AI Summarizer Performance:")
        logger.info(f"  Async: {async_ai_time:.2f}s ({async_summary_count} summaries)")

    logger.info("\n" + "="*60)

    # ä¿å­˜æŠ¥å‘Š
    report = f"""# æ€§èƒ½æµ‹è¯•æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}

## æµ‹è¯•ç»“æœ

### 1. çˆ¬è™«æ€§èƒ½å¯¹æ¯”

| ç‰ˆæœ¬ | è€—æ—¶ | é¡¹ç›®æ•° | æ€§èƒ½æå‡ |
|------|------|--------|----------|
| åŒæ­¥ç‰ˆæœ¬ | {sync_scraper_time:.2f}s | {sync_repo_count} | - |
| å¼‚æ­¥ç‰ˆæœ¬ | {async_scraper_time:.2f}s | {async_repo_count} | {scraper_speedup:.2f}x |

### 2. AI æ‘˜è¦ç”Ÿæˆæ€§èƒ½

| ç‰ˆæœ¬ | è€—æ—¶ | æ‘˜è¦æ•° |
|------|------|--------|
| å¼‚æ­¥ç‰ˆæœ¬ | {async_ai_time:.2f}s | {async_summary_count} |

## æ€»ç»“

- âœ… å¼‚æ­¥çˆ¬è™«æ€§èƒ½æå‡: **{scraper_speedup:.2f}x**
- âœ… å·²å…¨é¢è¿ç§»è‡³å¼‚æ­¥ AI æ‘˜è¦ç”Ÿæˆå™¨

## ä¼˜åŒ–ç‰¹æ€§

1. **å¹¶å‘æ§åˆ¶**: ä½¿ç”¨ Semaphore é™åˆ¶å¹¶å‘æ•°ï¼Œé¿å… API é™æµ
2. **é”™è¯¯é‡è¯•**: è‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚ï¼Œæé«˜æˆåŠŸç‡
3. **è¶…æ—¶æ§åˆ¶**: é¿å…é•¿æ—¶é—´é˜»å¡
4. **èµ„æºç®¡ç†**: è‡ªåŠ¨ç®¡ç†è¿æ¥æ± å’Œä¼šè¯
"""

    report_path = Path("performance_report.md")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)

    logger.success(f"Performance report saved to {report_path}")


if __name__ == "__main__":
    asyncio.run(main())
